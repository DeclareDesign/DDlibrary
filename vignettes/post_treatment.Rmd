---
title: "Post-Treatment Estimands"
output: rmarkdown::html_vignette
bibliography: bib.bib
vignette: >
  %\VignetteIndexEntry{Post-treatment}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r MIDA, echo = FALSE,include = FALSE}
library(DesignLibrary)
library(ggplot2)
library(knitr)
library(dplyr)
```


In designs that try to answer ''post-treatment'' questions, the outcome is conditioned by a variable that is itself a consequence of treatment. We consider this issue in the context of an audit experiment, a special case of a two-arm design. Audit experiments are designs in which we seek to study how public-facing actors -- bureaucrats, politicians, landlords, employers, etc. -- respond to requests by research confederates. By varying the attributes of the confederates experimentally, social scientists use audit studies to measure discrimination in diverse settings.

Consider an audit experiment that seeks to assess the effects of an email from a Latino name (versus a White name) on whether and how well election officials respond to requests for information. For example, do they use a positive or negative tone? These questions seem reasonable enough. The problem, however, is that if there are officials who don’t send responses, tone would be missing. More subtly, if there is an official that does send an email but would not have sent it in a different treatment condition, then tone is missing for one of their potential outcomes. That means that some of the variation we observe in tone due to treatment is being accounted for by response. Below we discuss the implications of this set up for our estimations.

## Design Declaration

  - **M**odel: The model has two outcome variables, $C_i$ and $Y_i$. $C_i$ stands for "conditional on response" and is equal to 1 if a response is sent, and 0 otherwise. $Y_i$ is the tone of the response and is normally distributed when it is defined. $Z_i$ is the treatment and equals 1 if the email is sent using a Latino name and 0 otherwise. The table below shows the potential outcomes for four possible types of subjects, depending on the potential outcomes of $C_i$. A types always respond regardless of treatment and D types never respond, regardless of treatment. B types respond if and only if they are treated, whereas C types respond if and only if they are not treated. The table also includes columns for the potential outcomes of $Y_i$, showing which potential outcome subjects would express depending on their type. The key thing to note is that for the B, C, and D types, the effect of treatment on $Y_i$ is undefined because we do not observe tone if messages are never sent. The last (and very important) feature of our model is that the outcomes $Y_i$ are possibly correlated with subject type. Even though both $E[$Y_i$(1)|Type = A]$ and $E[$Y_i$(1)|Type = B]$ exist, there's no reason to expect that they are the same. In the design we assume a distribution of types with roughly 50% A, 34% B, 14% C, and 2% D.

```{r, echo=FALSE}
design <- post_treatment_designer(N = 500)

causal_types <- draw_data(design) %>%
  select(type, C_Z_0, C_Z_1, Y_Z_0, Y_Z_1, Ystar_Z_0, Ystar_Z_1) %>%
  arrange(type) %>% unique()

kable(causal_types, caption = "Causal Types", row.names = FALSE)
```

- **I**nquiry: We have three inquiries. The first is straightforward: $E[C(1)-C(0)]$ is the Average Treatment Effect on response. The inquiry for the average treatment effect on tone ($E[Y(1) - Y(0)]$) is the undefined inquiry that does not have an answer (unless we are willing to consider complex potential outcomes, such as the tone of a response on a call that did not receive a response). We consider two additonal inquiries, defined as: $E[Y_i(1) - Y_i(0) | Type = A]$, which is the average effect of treatment on tone among A types, and $E[Y^*(1) - Y^*(0)]$, in which we specify an alternative outcome ($Y^*$) whereby we impute the value of 0 for missing tone observations.

- **D**ata strategy: The data strategy will be to use complete random assignment to assign 250 of 500 units to treatment.

- **A**nswer strategy: We’ll try to answer all three inquiries with the difference-in-means estimator, but as the diagnosis will reveal, this strategy works well for some inquiries but not others.

```{r,eval = TRUE, code = get_design_code(post_treatment_designer())}
```

## Takeaways

```{r}
diagnosis <- diagnose_design(post_treatment_design)
```

```{r, echo=FALSE}
kable(reshape_diagnosis(diagnosis)[, -c(1:2, 4:6)], digits = 2)
```

We learn four things from the design diagnosis. First, as expected, our experiment is unbiased for the average treatment effect on response.

Next, we see that our second inquiry, as well as our diagnostics for it, are undefined. The diagnosis tells us that our definition of potential outcomes produces a definition problem for the estimand. Note that the diagnosands that are defined, including power, depend only on the answer strategy and not on the estimand.

Our third estimand ---the average effect for the A types--- is defined but our estimates are biased. The reason for this is that we cannot tell from the data which types are the A types: we are not conditioning on the correct subset. Indeed, we are unable to condition on the correct subset. If a subject responds in the treatment group, we don’t know if she is an A or a B type; in the control group, we can’t tell if a responder is an A or a C type. Our difference-in-means estimator of the ATE on $Y$ among As will be off whenever As have different outcomes from Bs and Cs.

Finally, in some cases, the problem might be resolved by changing the inquiry. Closely related estimands can often be defined, perhaps by redefining $Y$ (e.g., emails never sent have a tone of zero). We observe that our alternative measure of tone (where we impute missing tone as "0") yields unbiased difference-in-means estimates. Estimating effects for unobserved subgroups, however, is a difficult challenge and requires careful consideration.

## Applications

This kind of problem is surprisingly common. Here are three more distinct instances of the problem:

1. $Y$ is the decision to vote Democrat ($Y = 1$) or Republican ($Y = 0$), $C$ is the decision to turn out to vote and $Z$ is a campaign message. The decision to vote may depend on treatment but if subjects do not vote then $Y$ is undefined.

2. $Y$ is the weight of infants, $C$ is whether a child is born and $Z$ is a maternal health intervention. Fertility may depend on treatment but the weight of unborn (possibly never conceived) babies is not defined.

3. $Y$ is the charity to whom contributions are made during fundraising and $C$ is whether anything is contributed and $Z$ is an encouragement to contribute. The identity of beneficiaries is not defined if there are no contributions.

All of these problem exhibit a form of post treatment bias (see section Post treatment bias) but the issue goes beyond picking the right estimator. Our problem here is conceptual: the effect of treatment on the outcome just doesn’t exist for some subjects.

## Using the Post Treatment Designer

In R, you can generate a post_treatment design using the template function `post_treatment_designer()` in the `DesignLibrary` package by running the following lines, which install and load the package:

```{r, eval=FALSE}
devtools::install_github("DeclareDesign/DesignLibrary", keep_source = TRUE)
library(DesignLibrary)
```

We can then create specific designs by defining values for each argument. For example, we create a design called `my_post_treatment_design` with `N` set to 500, by running the lines below.

```{r, eval=FALSE}
post_treatment_design <- post_treatment_designer(N = 500)
```

You can see more details on the `post_treatment_designer()` function and its arguments by running the following line of code:

```{r, eval=FALSE}
??post_treatment_designer
```